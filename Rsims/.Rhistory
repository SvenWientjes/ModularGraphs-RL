setwd("C:/Users/wient/OneDrive - UGent/Projects/ModularGraphs-RL/Rsims")
############################################################################################################################
############################ For testing with graphs that have 4 modules (and 24 nodes?) ###################################
############################################################################################################################
library(foreach)
library(ggplot2)
library(RColorBrewer)
# Load Functions from /src/
sapply(paste0('src/',list.files('src/')), source)
# Get different Defining Parameters
vStart <- 2    # Nr of starting node
vGoal  <- 8    # Nr of goal (terminating, rewarding) node
nSteps <- 15   # Nr of maximum steps in a miniblock (hitMat and EVcalc will use nSteps-1; agent simulations will use nSteps!)
gRew   <- 65   # Reward upon reaching vGoal
sCost  <- 1    # Points detracted from accumulated reward for each taken step
#Quad Schapiro-style edge matrix
Edges <- list(c(2, 3, 4, 20),
c(1, 3, 4, 5),
c(1, 2, 4, 5),
c(1, 2, 3, 5),
c(2, 3, 4, 6),
c(5, 7, 8, 9),
c(6, 8, 9, 10),
c(6, 7, 9, 10),
c(6, 7, 8, 10),
c(7, 8, 9, 11),
c(10,12,13,14),
c(11,13,14,15),
c(11,12,14,15),
c(11,12,13,15),
c(12,13,14,16),
c(15,17,18,19),
c(16,18,19,20),
c(16,17,19,20),
c(16,17,18,20),
c(17,18,19, 1))
# Describe unique nodes for QuadSchap
inspect.Vertices <- c(1, 2, 5, 6, 7, 16, 17)
# Describe identical nodes for QuadSchap
idmap <- list(a = c(1,15), b = c(2,3,4, 12,13,14), c = c(5,11), d = c(6,10), e = c(7,9), f = c(16,20), g = c(17,18,19))
hitMat <- read.csv('data/hitMat_quadSchap_step15.csv', row.names=1)
# Get the Expected Values for each interaction of previous & current node, conditional upon steps left
EVmat <- foreach(v = inspect.Vertices, .combine=rbind) %do% {
tempMat <- EVcalc(Edges=Edges, vGoal=vGoal, nSteps=nSteps-1, gRew=gRew, sCost=sCost, hitMat=hitMat, Vertex=v)
tempMat
}
piMat <- policy.generate(Edges=Edges, EVmat=EVmat, idmap=idmap)
piMat
# Plot the EV of the different nodes for certain steps left!
EVplot(EVmat=EVmat, piMat=piMat)
1 %in% c(1,2,3)
ModularStopper <- function(Edges, vStart, vGoal, nSteps, gRew, sCost, nTrials, modTrans, parNum=1, startRew=0){
parDat <- data.frame(pp=parNum, trial=1:nTrials, trRew=0, nSteps=0, endV=0, totRew=0, strat='Mstop')
totRew <- startRew
for(tr in 1:nTrials){
path   <- c(vStart, sample(Edges[[vStart]],1))
totRew <- totRew-sCost
trRew  <- -sCost
for(st in 2:(nSteps+1)){
if(tail(path,1)==vGoal){
totRew <- totRew+gRew
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=(trRew+gRew), nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else if(st==(nSteps+1) |(tail(path,1) %in% modTrans)){
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=trRew, nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else{
path <- c(path, sample(Edges[[tail(path,1)]],1))
totRew <- totRew - sCost
trRew  <- trRew  - sCost
}
}
}
return(parDat)
}
ModularStopper <- function(Edges, vStart, vGoal, nSteps, gRew, sCost, nTrials, modTrans, parNum=1, startRew=0){
parDat <- data.frame(pp=parNum, trial=1:nTrials, trRew=0, nSteps=0, endV=0, totRew=0, strat='Mstop')
totRew <- startRew
for(tr in 1:nTrials){
path   <- c(vStart, sample(Edges[[vStart]],1))
totRew <- totRew-sCost
trRew  <- -sCost
for(st in 2:(nSteps+1)){
if(tail(path,1)==vGoal){
totRew <- totRew+gRew
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=(trRew+gRew), nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else if(st==(nSteps+1) |( T %in% apply(modTrans, 1, function(x){identical(x, tail(path,2))}) )){
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=trRew, nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else{
path <- c(path, sample(Edges[[tail(path,1)]],1))
totRew <- totRew - sCost
trRew  <- trRew  - sCost
}
}
}
return(parDat)
}
rbind(c(1,20), c(6,5), c(10,11))
testMat <- rbind(c(1,20), c(6,5), c(10,11))
apply(testMat, 1, function(x){identical(x, c(6,5))})
apply(testMat, 1, function(x){identical(x, c(5,6))})
ModularStopper <- function(Edges, vStart, vGoal, nSteps, gRew, sCost, nTrials, modTrans, parNum=1, startRew=0){
parDat <- data.frame(pp=parNum, trial=1:nTrials, trRew=0, nSteps=0, endV=0, totRew=0, strat='Mstop')
totRew <- startRew
for(tr in 1:nTrials){
path   <- c(vStart, sample(Edges[[vStart]],1))
totRew <- totRew-sCost
trRew  <- -sCost
for(st in 2:(nSteps+1)){
if(tail(path,1)==vGoal){
totRew <- totRew+gRew
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=(trRew+gRew), nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else if(st==(nSteps+1) |( T %in% apply(modTrans, 1, function(x){identical(x, tail(path,2))}) )){
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=trRew, nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else{
path <- c(path, sample(Edges[[tail(path,1)]],1))
totRew <- totRew - sCost
trRew  <- trRew  - sCost
}
}
}
return(parDat)
}
ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=1, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11)))
# Get parameters for agentic simulations
nPP <- 500
nTr <- 100
# Get different Defining Parameters
vStart <- 2    # Nr of starting node
vGoal  <- 8    # Nr of goal (terminating, rewarding) node
nSteps <- 15   # Nr of maximum steps in a miniblock (hitMat and EVcalc will use nSteps-1; agent simulations will use nSteps!)
gRew   <- 65   # Reward upon reaching vGoal
sCost  <- 1    # Points detracted from accumulated reward for each taken step
#Quad Schapiro-style edge matrix
Edges <- list(c(2, 3, 4, 20),
c(1, 3, 4, 5),
c(1, 2, 4, 5),
c(1, 2, 3, 5),
c(2, 3, 4, 6),
c(5, 7, 8, 9),
c(6, 8, 9, 10),
c(6, 7, 9, 10),
c(6, 7, 8, 10),
c(7, 8, 9, 11),
c(10,12,13,14),
c(11,13,14,15),
c(11,12,14,15),
c(11,12,13,15),
c(12,13,14,16),
c(15,17,18,19),
c(16,18,19,20),
c(16,17,19,20),
c(16,17,18,20),
c(17,18,19, 1))
# Describe unique nodes for QuadSchap
inspect.Vertices <- c(1, 2, 5, 6, 7, 16, 17)
# Describe identical nodes for QuadSchap
idmap <- list(a = c(1,15), b = c(2,3,4, 12,13,14), c = c(5,11), d = c(6,10), e = c(7,9), f = c(16,20), g = c(17,18,19))
hitMat <- read.csv('data/hitMat_quadSchap_step15.csv', row.names=1)
# Get the Expected Values for each interaction of previous & current node, conditional upon steps left
EVmat <- foreach(v = inspect.Vertices, .combine=rbind) %do% {
tempMat <- EVcalc(Edges=Edges, vGoal=vGoal, nSteps=nSteps-1, gRew=gRew, sCost=sCost, hitMat=hitMat, Vertex=v)
tempMat
}
piMat <- policy.generate(Edges=Edges, EVmat=EVmat, idmap=idmap)
ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=1, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11)))
warnings()
ModularStopper <- function(Edges, vStart, vGoal, nSteps, gRew, sCost, nTrials, modTrans, parNum=1, startRew=0){
parDat <- data.frame(pp=parNum, trial=1:nTrials, trRew=0, nSteps=0, endV=0, totRew=0, strat='MStop')
totRew <- startRew
for(tr in 1:nTrials){
path   <- c(vStart, sample(Edges[[vStart]],1))
totRew <- totRew-sCost
trRew  <- -sCost
for(st in 2:(nSteps+1)){
if(tail(path,1)==vGoal){
totRew <- totRew+gRew
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=(trRew+gRew), nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else if(st==(nSteps+1) |( T %in% apply(modTrans, 1, function(x){identical(x, tail(path,2))}) )){
parDat[parDat$trial==tr,] <- data.frame(pp=parNum, trial=tr, trRew=trRew, nSteps=(length(path)-1), endV=tail(path,1), totRew=totRew, strat='MStop')
break
}else{
path <- c(path, sample(Edges[[tail(path,1)]],1))
totRew <- totRew - sCost
trRew  <- trRew  - sCost
}
}
}
return(parDat)
}
ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=1, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11)))
# Run several agents on this task, all encompassing different heuristics
AG.dat <- data.frame(pp=0, trial=0, trRew=0, nSteps=0, endV=0, totRew=0, strat='init')
for(pp in 1:nPP){
AG.dat <- rbind(AG.dat, RandomStopper( Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, LazyWaiter(    Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, RandomLengther(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, OptimalStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, piMat=piMat))
AG.dat <- rbind(AG.dat, ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11))))
}
AG.dat <- AG.dat[-1,]
AG.dat$strat <- droplevels(AG.dat$strat)
# Summarize agent simulations per participant
AG.dat.ppEval <- data.frame(pp=0, totRew=0, endV.p=0, strat='init')
for(pp in 1:nPP){
for(strat in levels(AG.dat$strat)){
totRew <- AG.dat[AG.dat$pp==pp & AG.dat$trial==max(AG.dat$trial) & AG.dat$strat==strat,]$totRew
endV.p <- sum(AG.dat[AG.dat$pp==pp & AG.dat$strat==strat,]$endV==vGoal)
AG.dat.ppEval <- rbind(AG.dat.ppEval, data.frame(pp=pp, totRew=totRew, endV.p=endV.p, strat=strat))
}
}
AG.dat.ppEval <- AG.dat.ppEval[-1,]
# Plot agent data!
ggplot(AG.dat.ppEval, aes(x=totRew, col=strat)) +
geom_density()
# Get parameters for agentic simulations
nPP <- 2000
# Run several agents on this task, all encompassing different heuristics
AG.dat <- data.frame(pp=0, trial=0, trRew=0, nSteps=0, endV=0, totRew=0, strat='init')
for(pp in 1:nPP){
AG.dat <- rbind(AG.dat, RandomStopper( Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, LazyWaiter(    Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, RandomLengther(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, OptimalStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, piMat=piMat))
AG.dat <- rbind(AG.dat, ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11))))
}
AG.dat <- AG.dat[-1,]
AG.dat$strat <- droplevels(AG.dat$strat)
# Summarize agent simulations per participant
AG.dat.ppEval <- data.frame(pp=0, totRew=0, endV.p=0, strat='init')
for(pp in 1:nPP){
for(strat in levels(AG.dat$strat)){
totRew <- AG.dat[AG.dat$pp==pp & AG.dat$trial==max(AG.dat$trial) & AG.dat$strat==strat,]$totRew
endV.p <- sum(AG.dat[AG.dat$pp==pp & AG.dat$strat==strat,]$endV==vGoal)
AG.dat.ppEval <- rbind(AG.dat.ppEval, data.frame(pp=pp, totRew=totRew, endV.p=endV.p, strat=strat))
}
}
AG.dat.ppEval <- AG.dat.ppEval[-1,]
# Plot agent data!
ggplot(AG.dat.ppEval, aes(x=totRew, col=strat)) +
geom_density()
AG.dat
ggplot(AG.dat, aes(x=nSteps, col=strat)) +
geom_density()
ggplot(AG.dat, aes(col=strat)) +
geom_bar(nSteps)
ggplot(AG.dat, aes(col=strat)) +
geom_bar(aes(nSteps))
ggplot(AG.dat, aes(col=strat)) +
geom_bar(aes(nSteps), position='dodge')
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge')
AG.dat[AG.dat$strat=='OS',]
AG.dat[AG.dat$strat=='OS',]$nSteps
AG.dat[AG.dat$strat=='OS' & AG.dat$nSteps==1,]$nSteps
AG.dat[AG.dat$strat=='OS' & AG.dat$nSteps==1,]
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_discrete(breaks=1:15)
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_discrete(breaks=1:15, labels=1:15)
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_discrete(breaks=15, labels=1:15)
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_continuous(breaks=1:15, labels=1:15)
# Plot agent data!
ggplot(AG.dat.ppEval, aes(x=totRew, col=strat)) +
geom_density()
20*3
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_continuous(breaks=1:15, labels=1:15)
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=strat)) +
geom_line()
AG.dat[AG.dat$strat %in% c('OS','MStop'),]
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=interaction(strat,pp))) +
geom_line()
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=pp)) +
geom_line() +
facet_wrap(strat)
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=pp)) +
geom_line() +
facet_wrap(strat)
AG.dat[AG.dat$strat %in% c('OS','MStop'),]
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=pp)) +
geom_line() +
facet_wrap(strat)
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=pp)) +
geom_line()
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat %in% c('OS','MStop'),], aes(x=trial, y=totRew, col=pp)) +
geom_line() +
facet_grid(strat) +
theme(legend.position='none')
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS',], aes(x=trial, y=totRew, col=pp)) +
geom_line() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS' | AG.dat$strat=='MStop',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS' | AG.dat$strat=='MStop',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_grid(strat) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS' | AG.dat$strat=='MStop',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_grid(strat~) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat[AG.dat$strat == 'OS' | AG.dat$strat=='MStop',], aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_grid(~strat) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(strat) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(AG.dat$strat) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(AG.dat$strat) +
geom_hline(yintercept=0, color='red') +
geom_smooth()+
theme(legend.position='none')
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(AG.dat$strat) +
geom_hline(yintercept=0, color='red') +
geom_smooth()+
theme(legend.position='none')
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(AG.dat$strat) +
#geom_hline(yintercept=0, color='red') +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp), ) +
facet_wrap(AG.dat$strat) +
geom_hline(yintercept=0) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
facet_wrap(AG.dat$strat) +
geom_smooth()+
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
geom_hline(yintercept=0) +
facet_wrap(AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
geom_abline(aes(y=0)) +
facet_wrap(AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
geom_abline(slope=0, intercept=0) +
facet_wrap(AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
facet_wrap(AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
facet_grid(.~AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
##### Get candidate cost-reward setups that have decent optimal behavioural signatures -----
candidates <- data.frame(gRew = 0, sCost = 0)
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat, aes(x=trial, y=totRew, col=pp)) +
geom_line(aes(group=pp)) +
geom_hline(yintercept=0, color='red') +
facet_grid(.~AG.dat$strat) +
geom_smooth() +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat) +
geom_line(aes(x=trial, y=totRew, col=pp, group=pp)) +
geom_hline(yintercept=0, color='red') +
facet_grid(.~AG.dat$strat) +
geom_smooth(aes(x=trial, y=totRew, col=pp)) +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat) +
geom_line(aes(x=trial, y=totRew, col=pp, group=pp)) +
facet_grid(.~AG.dat$strat) +
geom_smooth(aes(x=trial, y=totRew, col=pp)) +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat) +
geom_line(aes(x=trial, y=totRew, col=pp, group=pp)) +
facet_grid(.~strat) +
geom_smooth(aes(x=trial, y=totRew, col=pp)) +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat) +
geom_line(aes(x=trial, y=totRew, col=pp, group=pp)) +
geom_hline(yintercept=0) +
facet_grid(.~strat) +
geom_smooth(aes(x=trial, y=totRew, col=pp)) +
theme(legend.position='none')
# Plot accumulated reward over time for different strategies (focus on OS and MStop)
ggplot(AG.dat) +
geom_line(aes(x=trial, y=totRew, col=pp, group=pp)) +
geom_hline(yintercept=0, color='red') +
facet_grid(.~strat) +
geom_smooth(aes(x=trial, y=totRew, col=pp)) +
theme(legend.position='none')
# Plot agent data!
ggplot(AG.dat.ppEval, aes(x=totRew, col=strat)) +
geom_density()
# Get parameters for agentic simulations
nPP <- 2000
nTr <- 200
# Run several agents on this task, all encompassing different heuristics
AG.dat <- data.frame(pp=0, trial=0, trRew=0, nSteps=0, endV=0, totRew=0, strat='init')
for(pp in 1:nPP){
AG.dat <- rbind(AG.dat, RandomStopper( Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, LazyWaiter(    Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, RandomLengther(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0))
AG.dat <- rbind(AG.dat, OptimalStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, piMat=piMat))
AG.dat <- rbind(AG.dat, ModularStopper(Edges=Edges, vStart=vStart, vGoal=vGoal, nSteps=nSteps, gRew=gRew, sCost=sCost, nTrials=nTr, parNum=pp, startRew=0, modTrans=rbind(c(1,20),c(6,5),c(10,11))))
}
AG.dat <- AG.dat[-1,]
AG.dat$strat <- droplevels(AG.dat$strat)
# Summarize agent simulations per participant
AG.dat.ppEval <- data.frame(pp=0, totRew=0, endV.p=0, strat='init')
for(pp in 1:nPP){
for(strat in levels(AG.dat$strat)){
totRew <- AG.dat[AG.dat$pp==pp & AG.dat$trial==max(AG.dat$trial) & AG.dat$strat==strat,]$totRew
endV.p <- sum(AG.dat[AG.dat$pp==pp & AG.dat$strat==strat,]$endV==vGoal)
AG.dat.ppEval <- rbind(AG.dat.ppEval, data.frame(pp=pp, totRew=totRew, endV.p=endV.p, strat=strat))
}
}
AG.dat.ppEval <- AG.dat.ppEval[-1,]
# Plot agent data!
ggplot(AG.dat.ppEval, aes(x=totRew, col=strat)) +
geom_density()
# Plot nSteps for every agent
ggplot(AG.dat, aes(fill=strat)) +
geom_bar(aes(nSteps), position='dodge') +
scale_x_continuous(breaks=1:15, labels=1:15)
